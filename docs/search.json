[
  {
    "objectID": "fitting-exercise/fitting-exercise.html",
    "href": "fitting-exercise/fitting-exercise.html",
    "title": "Fitting Exercise",
    "section": "",
    "text": "For this assignment, I will be using data on a drug candidate called Mavoglurant from the paper:\nWendling, T., Dumitras, S., Ogungbenro, K. et al. Application of a Bayesian approach to physiological modelling of mavoglurant population pharmacokinetics. J Pharmacokinet Pharmacodyn 42, 639–657 (2015). https://doi.org/10.1007/s10928-015-9430-4\n\n\nFirst we will load the data and additional packages necessary for the assigniment.\n\nlibrary(readr) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/mutsa_n/Desktop/MADA-course/mutsanyamuranga-MADA-portfolio\n\nlibrary(ggplot2) # for plots\nlibrary(gtsummary)# for summary tables\n\n#BlackLivesMatter\n\nlibrary(patchwork) #for combine plots\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5      ✔ rsample      1.2.0 \n✔ dials        1.2.1      ✔ tibble       3.2.1 \n✔ infer        1.0.6      ✔ tune         1.1.2 \n✔ modeldata    1.3.0      ✔ workflows    1.1.4 \n✔ parsnip      1.2.0      ✔ workflowsets 1.0.1 \n✔ purrr        1.0.2      ✔ yardstick    1.2.0 \n✔ recipes      1.0.10     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ recipes::all_double()  masks gtsummary::all_double()\n✖ recipes::all_factor()  masks gtsummary::all_factor()\n✖ recipes::all_integer() masks gtsummary::all_integer()\n✖ recipes::all_logical() masks gtsummary::all_logical()\n✖ recipes::all_numeric() masks gtsummary::all_numeric()\n✖ purrr::discard()       masks scales::discard()\n✖ dplyr::filter()        masks stats::filter()\n✖ dplyr::lag()           masks stats::lag()\n✖ yardstick::spec()      masks readr::spec()\n✖ recipes::step()        masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\nI will also load the data from the another paper which has used this data to ensure a level of consistency and ease of usage with the data.\n\n# Loading Data through CSV\nmavodrug &lt;-- read.csv('Mavoglurant_A2121_nmpk.csv')\nmavodrug &lt;- abs(mavodrug)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#loading",
    "href": "fitting-exercise/fitting-exercise.html#loading",
    "title": "Fitting Exercise",
    "section": "",
    "text": "First we will load the data and additional packages necessary for the assigniment.\n\nlibrary(readr) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/mutsa_n/Desktop/MADA-course/mutsanyamuranga-MADA-portfolio\n\nlibrary(ggplot2) # for plots\nlibrary(gtsummary)# for summary tables\n\n#BlackLivesMatter\n\nlibrary(patchwork) #for combine plots\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n\n✔ broom        1.0.5      ✔ rsample      1.2.0 \n✔ dials        1.2.1      ✔ tibble       3.2.1 \n✔ infer        1.0.6      ✔ tune         1.1.2 \n✔ modeldata    1.3.0      ✔ workflows    1.1.4 \n✔ parsnip      1.2.0      ✔ workflowsets 1.0.1 \n✔ purrr        1.0.2      ✔ yardstick    1.2.0 \n✔ recipes      1.0.10     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ recipes::all_double()  masks gtsummary::all_double()\n✖ recipes::all_factor()  masks gtsummary::all_factor()\n✖ recipes::all_integer() masks gtsummary::all_integer()\n✖ recipes::all_logical() masks gtsummary::all_logical()\n✖ recipes::all_numeric() masks gtsummary::all_numeric()\n✖ purrr::discard()       masks scales::discard()\n✖ dplyr::filter()        masks stats::filter()\n✖ dplyr::lag()           masks stats::lag()\n✖ yardstick::spec()      masks readr::spec()\n✖ recipes::step()        masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\nI will also load the data from the another paper which has used this data to ensure a level of consistency and ease of usage with the data.\n\n# Loading Data through CSV\nmavodrug &lt;-- read.csv('Mavoglurant_A2121_nmpk.csv')\nmavodrug &lt;- abs(mavodrug)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#summary-tables",
    "href": "fitting-exercise/fitting-exercise.html#summary-tables",
    "title": "Fitting Exercise",
    "section": "Summary Tables",
    "text": "Summary Tables\nThe summary tables provide a quick overview of the numerical and categorical variables in the dataset.\n\nmavotable1 &lt;- tbl_summary(\n  cleaned_mavo,\n  by = DOSE, # Stratify summary by DOSE\n  type = list(\n    DOSE ~ \"categorical\", #Specifying DOSE as categorical\n    SEX ~ \"categorical\",  #Specifying SES as categorical\n    Y ~ \"continuous2\",\n    AGE ~ \"continuous2\",\n    WT ~ \"continuous2\",\n    HT ~ \"continuous2\"\n  ),\n  statistic = list(\n    all_continuous() ~ c(\"{mean} ({sd})\", \"{min}, {max}\"), # Statistics for continuous variables\n    all_categorical() ~ \"{n} ({p}%)\"), # Statistics for categorical variables\n  missing = \"no\" # Option to exclude missing data in summary\n)\n\nmavotable1\n\n\n\n\n\n  \n    \n      Characteristic\n      25, N = 591\n      37.5, N = 121\n      50, N = 491\n    \n  \n  \n    Y\n\n\n\n        Mean (SD)\n1,783 (601)\n2,464 (488)\n3,239 (787)\n        Range\n826, 3,866\n1,801, 3,463\n1,949, 5,607\n    AGE\n\n\n\n        Mean (SD)\n32 (9)\n36 (10)\n33 (9)\n        Range\n18, 49\n19, 50\n18, 49\n    SEX\n\n\n\n        1\n49 (83%)\n10 (83%)\n45 (92%)\n        2\n10 (17%)\n2 (17%)\n4 (8.2%)\n    WT\n\n\n\n        Mean (SD)\n81 (12)\n81 (11)\n84 (13)\n        Range\n58, 111\n64, 102\n57, 115\n    HT\n\n\n\n        Mean (SD)\n1.76 (0.09)\n1.75 (0.10)\n1.76 (0.08)\n        Range\n1.56, 1.91\n1.56, 1.91\n1.52, 1.93\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#plots",
    "href": "fitting-exercise/fitting-exercise.html#plots",
    "title": "Fitting Exercise",
    "section": "Plots",
    "text": "Plots\nThese plots show the relationship between the total drug (‘Y’) and other predictors such as age, dose, and sex. Scatterplots help visualize the continuous relationship between ‘Y’ and age, while boxplots illustrate the distribution of ‘Y’ across different levels of dose and sex.\n\nmavoplot2 &lt;- cleaned_mavo %&gt;%\n  mutate(DOSE = as.factor(DOSE)) %&gt;% # Convert DOSE to factor here\n  ggplot(aes(x = AGE, y = Y, group = DOSE, col = DOSE)) +\n  geom_point() + \n  geom_smooth(method = lm, se = FALSE) + # Add a linear regression line\n  scale_color_viridis_d(option = \"plasma\", end = .7)+\n  labs(title = \"Scatterplot of Y vs. AGE\", x = \"Age\", y = \"Total Drug (Y)\") +\n  theme_minimal()\nmavoplot2\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nmavoplot3 &lt;- cleaned_mavo %&gt;%\n  mutate(DOSE = as.factor(DOSE)) %&gt;% # Convert DOSE to factor here\n  ggplot(aes(x = HT, y = Y, group = DOSE, col = DOSE)) +\n  geom_point() + \n  geom_smooth(method = lm, se = FALSE) + # Add a linear regression line\n  scale_color_viridis_d(option = \"inferno\", end = .7)+\n  labs(title = \"Scatterplot of Y vs. HT\", x = \"HT\", y = \"Total Drug (Y)\") +\n  theme_minimal()\nmavoplot3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nmavoplot4&lt;-cleaned_mavo %&gt;%\n  mutate(DOSE = as.factor(DOSE)) %&gt;% # Convert DOSE to factor here\n  ggplot(aes(x = WT, y = Y, group = DOSE, col = DOSE)) +\n  geom_point() + \n  geom_smooth(method = lm, se = FALSE) + # Add a linear regression line\n  scale_color_viridis_d(option = \"magma\", end = .7)+\n  labs(title = \"Scatterplot of Y vs. WT\", x = \"WT\", y = \"Total Drug (Y)\") +\n  theme_minimal()\nmavoplot4\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nmavoplot5 &lt;- cleaned_mavo %&gt;%\n  mutate(DOSE = as.factor(DOSE)) %&gt;% # Converting DOSE to factor only for the plot\n  ggplot(aes(x = DOSE, y = Y, fill = DOSE)) + \n  geom_boxplot() + \n  labs(title = \"Distribution of Y by DOSE\", x = \"DOSE\", y = \"Y\") +\n  theme_minimal()\nmavoplot5\n\n\n\nmavoplot6 &lt;- cleaned_mavo %&gt;%\n  mutate(DOSE = as.factor(DOSE)) %&gt;% # Convert DOSE to factor here\n  select(DOSE, SEX) %&gt;%\n  pivot_longer(everything(), names_to = \"name\", values_to = \"value\") %&gt;%\n  mutate(name = factor(name, levels = c(\"DOSE\", \"SEX\"))) %&gt;%\n  ggplot(aes(x = value, fill = name)) +\n  geom_bar(alpha = 0.5, color = \"black\") +\n  facet_wrap(~name, scales = \"free\") +\n  scale_fill_manual(values = c(\"DOSE\" = \"lightgreen\", \"SEX\" = \"salmon\"))\nmavoplot6\n\n\n\n#Saving the figure in the folder\nmavoplot2_file &lt;- here(\"fitting-exercise\", \"YxAgexDose.png\")\nggsave(filename = mavoplot2_file, plot=mavoplot2, bg=\"white\")\n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\nmavoplot3_file &lt;- here(\"fitting-exercise\", \"YxHTxDose.png\")\nggsave(filename = mavoplot3_file, plot=mavoplot3, bg=\"white\")\n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\nmavoplot4_file &lt;- here(\"fitting-exercise\", \"YxWTxDose.png\")\nggsave(filename = mavoplot4_file, plot=mavoplot4, bg=\"white\")\n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\nmavoplot5_file &lt;- here(\"fitting-exercise\", \"factorplots.png\")\nggsave(filename = mavoplot5_file, plot=mavoplot5, bg=\"white\")\n\nSaving 7 x 5 in image\n\nmavoplot6_file &lt;- here(\"fitting-exercise\", \"YxDose.png\")\nggsave(filename = mavoplot6_file, plot=mavoplot6, bg=\"white\")\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#distributions-of-variables",
    "href": "fitting-exercise/fitting-exercise.html#distributions-of-variables",
    "title": "Fitting Exercise",
    "section": "Distributions of Variables",
    "text": "Distributions of Variables\nThese histograms visualize the distributions of variables such as total drug (‘Y’), age, weight (‘WT’), and height (‘HT’). They help identify any potential outliers or unusual patterns in the data.\n\nmavohist1 &lt;-\n  cleaned_mavo %&gt;%\n  select(Y, AGE, WT, HT) %&gt;%\n  pivot_longer(everything()) %&gt;%\n  mutate(name = factor(name, levels = c(\"Y\", \"AGE\", \"WT\", \"HT\"))) %&gt;%  #Keeps the order of plot\n  ggplot(aes(x = value, fill = name)) +\n  geom_histogram(alpha = 0.5, color=\"black\") +\n  facet_wrap(~name, scales = \"free\") +\n  scale_fill_manual(values = c(\"Y\" = \"green\", \"AGE\" = \"blue\", \"WT\" = \"grey\", \"HT\" = \"salmon\")) +\n  theme_minimal()\nmavohist1\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n#Saving the figure in the folder\nmavohist1_file &lt;- here(\"fitting-exercise\", \"histo_plots.png\")\nggsave(filename = mavohist1_file, plot=mavohist1, bg=\"white\")\n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#paircorrelation-plots",
    "href": "fitting-exercise/fitting-exercise.html#paircorrelation-plots",
    "title": "Fitting Exercise",
    "section": "Pair/Correlation Plots",
    "text": "Pair/Correlation Plots\nThe pair plot provides a visual overview of the relationships between the variables ‘Y’, age, weight, and height. The correlation matrix quantifies the strength and direction of the linear relationships between these variables. It helps identify potential multicollinearity issues and informs feature selection for modeling purposes.\n\n# Using the pairs function for selected variables\nmavo_matrix &lt;- pairs(cleaned_mavo[, c(\"Y\", \"AGE\", \"WT\", \"HT\")], \n      main = \"Pairwise Scatterplot Matrix\")\n\n\n\nmavo_matrix\n\nNULL\n\n#Saving the figure in the folder\ncorrel_file &lt;- here(\"fitting-exercise\", \"pair_matrix.png\")\nggsave(filename = correl_file, plot=mavo_matrix, bg=\"white\")\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#results",
    "href": "fitting-exercise/fitting-exercise.html#results",
    "title": "Fitting Exercise",
    "section": "Results",
    "text": "Results\nThe RMSE is approximately 654.5275. Lower values of RMSE indicate better model performance, as they imply smaller errors between predicted and actual values. The R-squared value is approximately 0.492, suggesting that the model explains about 49.2% of the variance in the outcome variable."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#linear-model",
    "href": "fitting-exercise/fitting-exercise.html#linear-model",
    "title": "Fitting Exercise",
    "section": "Linear Model",
    "text": "Linear Model\nTwo linear models are fitted to the continuous outcome (Y) of the train data. The first uses only the main predictor of interest DOSE, and the second uses all predictors. A null model is also fitted.\n\n#For reproducibility\nset.seed(rngseed)\n\n#Using linear regression function from tidymodels.\nmavo2lin_mod &lt;- linear_reg() %&gt;% set_engine(\"lm\") \n\n#Fit Y on Dose\nmavlinfit_dose &lt;- mavo2lin_mod%&gt;%fit(Y ~ DOSE, data = mavo2train_data)\n\n#Fit Y on All variables in the data\nmavlinfit_all &lt;- mavo2lin_mod%&gt;%fit(Y~., data= mavo2train_data)\n\n# Fitting a null model using tidymodels' parsnip engine\nmavo2null_mod &lt;- null_model() %&gt;% set_engine(\"parsnip\") %&gt;% set_mode(\"regression\")\nmavlinfit_null &lt;- mavo2null_mod %&gt;%\n  fit(Y ~ 1, data = mavo2train_data)\n\n#Use tidy for clean formatting of table\ntidy(mavlinfit_dose)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    535.     244.        2.19 3.08e- 2\n2 DOSE            53.4      6.29      8.50 4.41e-13\n\ntidy(mavlinfit_all)\n\n# A tibble: 6 × 5\n  term         estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  4397.      2170.      2.03   4.59e- 2\n2 DOSE           55.3        5.83    9.49   6.09e-15\n3 AGE            -0.417      9.50   -0.0439 9.65e- 1\n4 SEX2         -569.       285.     -1.99   4.95e- 2\n5 WT            -22.6        7.65   -2.96   4.00e- 3\n6 HT          -1130.      1358.     -0.832  4.08e- 1\n\ntidy(mavlinfit_null)\n\n# A tibble: 1 × 1\n  value\n  &lt;dbl&gt;\n1 2509.\n\n\nBoth the first and second models indicate a positve relationship between Y and DOSE. Furthermore, the second model implies that even when considering the influence of other factors, Y shows a positive correlation with AGE and a negative correlation with both WT and HT. With all other factors held constant, a change in the SEX variable from 1 to 2 is expected to result in a decrease in Y."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#root-mean-square-error",
    "href": "fitting-exercise/fitting-exercise.html#root-mean-square-error",
    "title": "Fitting Exercise",
    "section": "Root Mean Square Error",
    "text": "Root Mean Square Error\nSubsequently, RMSE metrics are calculated for all models using the methods outlined by Dr. Handel for solving module 8 exercises.\n\n#Computing the RMSE for model 1\nmavmetrics_dose &lt;- mavlinfit_dose %&gt;%\n  predict(mavo2train_data) %&gt;%\n  bind_cols(mavo2train_data)%&gt;%\n  metrics(truth=Y, estimate=.pred)\n\n#Computing the RMSE for model 2\nmavmetrics_all &lt;- mavlinfit_all %&gt;%\n  predict(mavo2train_data) %&gt;%\n  bind_cols(mavo2train_data)%&gt;%\n  metrics(truth=Y, estimate=.pred)\n\n#Computing the RMSE for model 3\nmavmetrics_null &lt;- mavlinfit_null %&gt;%\n  predict(mavo2train_data) %&gt;%\n  bind_cols(mavo2train_data)%&gt;%\n  metrics(truth=Y, estimate=.pred)\n\n\n#print the results\nprint(mavmetrics_null)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        948.\n2 rsq     standard         NA \n3 mae     standard        765.\n\nprint(mavmetrics_dose)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     703.   \n2 rsq     standard       0.451\n3 mae     standard     546.   \n\nprint(mavmetrics_all)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     627.   \n2 rsq     standard       0.562\n3 mae     standard     486.   \n\n\nThe RMSE values stand at 948, 702, and 627 for the null model, the model with only DOSE, and the model with all predictors, respectively. RMSE serves as a gauge for the average disparity between the model’s predicted values and the actual data. A lower RMSE signifies a superior fit to the data. Consequently, based on the RMSE metrics, the linear model comprising all predictor variables demonstrates superior performance compared to the other two models."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#cross-validation",
    "href": "fitting-exercise/fitting-exercise.html#cross-validation",
    "title": "Fitting Exercise",
    "section": "Cross-Validation",
    "text": "Cross-Validation\nFollowing that, the model performance is evaluated using the cross-validation technique employing 10 folds for the two main models. This technique involves dividing the training data into 10 subsets and iteratively using 9 of them for model fitting while reserving the remaining 10% for evaluation. This process is repeated 10 times, ensuring that each subset serves as both training and evaluation data.\n\n#setting the random seed for reproducibility\nset.seed(rngseed)\n\nfolds &lt;-vfold_cv(mavo2train_data, v=10)\nfolds\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits         id    \n   &lt;list&gt;         &lt;chr&gt; \n 1 &lt;split [81/9]&gt; Fold01\n 2 &lt;split [81/9]&gt; Fold02\n 3 &lt;split [81/9]&gt; Fold03\n 4 &lt;split [81/9]&gt; Fold04\n 5 &lt;split [81/9]&gt; Fold05\n 6 &lt;split [81/9]&gt; Fold06\n 7 &lt;split [81/9]&gt; Fold07\n 8 &lt;split [81/9]&gt; Fold08\n 9 &lt;split [81/9]&gt; Fold09\n10 &lt;split [81/9]&gt; Fold10\n\n\nSubsequently, an object for resampling is constructed using the ‘workflow’ function from tidymodels. This function combines pre-processing, modeling, and post-processing instructions into a single entity, streamlining the analysis pipeline.\n\n#setting the random seed for reproducibility\nset.seed(rngseed)\n\n#Resampling using workflow for the model with only DOSE as predictor\nmavlinfit_dose2 &lt;- \n    workflow() %&gt;%\n    add_model(mavo2lin_mod) %&gt;%\n  add_formula(Y ~ DOSE)%&gt;%\n    fit_resamples(folds)\n\n#Resampling using workflow for for the model with all predictors\nmavlinfit_all2 &lt;- \n    workflow() %&gt;%\n    add_model(mavo2lin_mod) %&gt;%\n  add_formula(Y ~ .)%&gt;%\n    fit_resamples(folds)\n\n#extracting the performance statistics results created from the 10 assessment sets. \n\ncollect_metrics(mavlinfit_dose2)\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   691.       10 67.5    Preprocessor1_Model1\n2 rsq     standard     0.512    10  0.0592 Preprocessor1_Model1\n\ncollect_metrics(mavlinfit_all2)\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   646.       10 64.8    Preprocessor1_Model1\n2 rsq     standard     0.573    10  0.0686 Preprocessor1_Model1\n\n\nThe implementation of 10-fold cross-validation resulted in a notable alteration in the RMSE values of the models. Specifically, for the model containing only the DOSE predictor, the RMSE decreased to 690 from the original 702 observed during training data utilization without cross-validation. Conversely, the model incorporating all predictors saw its RMSE increase to 645 with 10-fold cross-validation, compared to the initial value of 627 without it.\nIn contrast to the train/test model without cross-validation, the 10-fold cross-validation computes 10 distinct RMSE values for each sample and then averages these values. This process introduces variability among the resulting RMSEs. Further analysis indicated that the full model displays a smaller standard error of 64.81 for RMSE, in contrast to the 67.49 observed for the model including only the DOSE predictor.\n\nCV-repeat\nLastly, the 10-fold cross-validation modeling is repeated to assess the variation in the metric when employing a different randomization seed.\n\n#setting a different random seed\nset.seed(222)\n\n#Assigning 75% of the data into the training set\nmavodata_split2 &lt;- initial_split(mavo2, prop = .75)\n\n#Creating data frames for the train and test data\nmavotrain_data2 &lt;- training(mavodata_split2)\nmavotest_data2 &lt;- testing(mavodata_split2)\n\nPreparing the data for 10-fold cross-validation.\n\n#setting a different random seed\nset.seed(222)\n\n#Creating 10 random samples of the newly generated training data\nfolds2 &lt;-vfold_cv(mavotrain_data2, v=10)\nfolds2\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits         id    \n   &lt;list&gt;         &lt;chr&gt; \n 1 &lt;split [81/9]&gt; Fold01\n 2 &lt;split [81/9]&gt; Fold02\n 3 &lt;split [81/9]&gt; Fold03\n 4 &lt;split [81/9]&gt; Fold04\n 5 &lt;split [81/9]&gt; Fold05\n 6 &lt;split [81/9]&gt; Fold06\n 7 &lt;split [81/9]&gt; Fold07\n 8 &lt;split [81/9]&gt; Fold08\n 9 &lt;split [81/9]&gt; Fold09\n10 &lt;split [81/9]&gt; Fold10\n\n\nUsing the workflow to compute both the models.\n\n#setting the random seed for reproducibility\nset.seed(222)\n\n#Resampling using workflow for the model with only DOSE as predictor\nmavolinfit_dose3 &lt;- workflow() %&gt;%\n    add_model(mavo2lin_mod) %&gt;%\n  add_formula(Y ~ DOSE)%&gt;%\n    fit_resamples(folds2)\n\n#Resampling using workflowfor for the model with all predictors\nmavolinfit_all3 &lt;- workflow() %&gt;%\n    add_model(mavo2lin_mod) %&gt;%\n  add_formula(Y ~ .)%&gt;%\n    fit_resamples(folds2)\n\n#extracting the performance statistics results created from the 10 assessment sets. \n\ncollect_metrics(mavolinfit_dose3)\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   665.       10 67.9    Preprocessor1_Model1\n2 rsq     standard     0.553    10  0.0608 Preprocessor1_Model1\n\ncollect_metrics(mavolinfit_all3)\n\n# A tibble: 2 × 6\n  .metric .estimator    mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   635.       10 65.4    Preprocessor1_Model1\n2 rsq     standard     0.600    10  0.0691 Preprocessor1_Model1"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-prediction",
    "href": "fitting-exercise/fitting-exercise.html#model-prediction",
    "title": "Fitting Exercise",
    "section": "Model Prediction",
    "text": "Model Prediction\nI first create three data frames that combines the observed and predicted values from the 3 original model fits to all of the training data.\n\n# Creating a data-frame with observed and predicted values from the model with `DOSE` as the predictor\ndose_fit &lt;- mavlinfit_dose %&gt;%\n  predict(mavo2train_data) %&gt;%\n  bind_cols(mavo2train_data)\n\n# Creating a data-frame with observed and predicted values from the model with everything as the predictor\nall_fit &lt;- mavlinfit_all %&gt;%\n  predict(mavo2train_data) %&gt;%\n  bind_cols(mavo2train_data)\n\n# Creating a data-frame with observed and predicted values from the model\nnull_fit &lt;- mavlinfit_null %&gt;%\n  predict(mavo2train_data) %&gt;%\n  bind_cols(mavo2train_data)\n\nUsing ChatGPT, the following few lines were created to add a labeled column to each dataframe. Each data frames now have 90 observations and 8 variables each. After that, I combine all of the data frames with rbind() function. This leads to 270 observations and 8 variables, they are easily differentiable by the newly created label column.\n\n# For the dose_fit data frame, I added a label column and dubbed it 'Dose model'\ndose_fit$label &lt;- rep(\"Dose Model\")\n\n# For all_fit data frame, , I added a label column and dubbed it 'All model'\nall_fit$label &lt;- rep(\"All Model\")\n\n# For null_fit data frame, , I added a label column and dubbed it 'Null model'\nnull_fit$label &lt;- rep(\"Null Model\")\n\n# I combined the three different data frames, so I can create a graph with it with greater ease. \ncombined_fit &lt;- rbind(dose_fit, all_fit, null_fit)\n\nI then use ggplot to create plot to reflect how the model predictions performs visually. The plots differentiate each of the models by the label with color and shape for the data points. The graph plots the observed value vs the predicted value. A good model would have fairly similar predicted values to its observed value. Visually, that would show a more 1:1 or linear relationship. When observing the graph we created in p1 and p2, it becomes obvious that the model with all of the predictors show the greatest predictions. The Dose model and hte Null model both shows flat lines, which is easily explained by the properties of a null model and the distinct factor level characteristics of the DOSE predictor.\n\n# Create the ggplot figure to graph the predictive values vs the observed value for the three models\np1 &lt;- ggplot(\n  combined_fit, aes(x = Y, y = .pred, color = label, shape = label)) +\n  geom_point(size=2) +\n   scale_color_manual(values = c(\"#9467bd\", \"#ff9896\", \"#17becf\"))+\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +  # Adding a 45-degree line\n  labs(x = \"Observed Values\", y = \"Predicted Values\", color = \"Model\", shape = \"Model\") +\n  xlim(0, 5000) + \n  ylim(0, 5000)+\n  theme_bw()\n\n# Viewing the plot\np1\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe All Model does most clearly follow the 45 degree angle line compare to the other two models. Despite that, the All Model still shows some variation in the data points, which can be explained by other factors.\n\n# Create the same ggplot figure with facets\np2 &lt;- ggplot(\n  combined_fit, aes(x = Y, y = .pred, color = label)) +\n  geom_point() +\n  scale_color_manual(values = c(\"#9467bd\", \"#ff9896\", \"#17becf\"))+\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\") +  # Adding a 45-degree line\n  labs(x = \"Observed Values\", y = \"Predicted Values\", color = \"Model\", shape = \"Model\") +\n  theme_minimal() +\n  facet_wrap(~ label, scales = \"free\")+ # Faceting by label (model)\n  xlim(0, 5000) + ylim(0, 5000)\n# Viewing the plot\np2\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\nI start with creating a column for residuals in the all_fit dataframe. I then plot the residuals versus the predicted to observe the patterns. The plot clearly shows a greater number of negative values compared to positive values, showing that there may be other factos still playing a role in affecting the data.\n\nall_fit &lt;- all_fit %&gt;%\n  mutate(residuals = .pred - Y)\n\np3 &lt;- ggplot(all_fit, aes(x = .pred, y = residuals)) +\n  geom_point(size = 2, color = \"#ff9896\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +  # Adding a line at y = 0\n  labs(x = \"Predicted Values\", y = \"Residuals\") +  # Corrected axis labels\n  ylim(-2500, 2500) +\n  theme_bw()\n\np3"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-prediction-and-uncertainty",
    "href": "fitting-exercise/fitting-exercise.html#model-prediction-and-uncertainty",
    "title": "Fitting Exercise",
    "section": "Model Prediction and Uncertainty",
    "text": "Model Prediction and Uncertainty\nThe following would be an attempt at calculating for uncertainty. This will be attempted by using 100 bootstrap samples. The following lines sets up a seed and creates 100 bootstraps into a object called bootstrap_100.\n\n# Set Seed for reproducibility\nset.seed(rngseed)\n\n# Creating 100 bootstraps using the training data\nbootstrap_100 &lt;- bootstraps(mavo2train_data, times=100)\n\nI created a function called fit_and_predict that allowed me to loop through each bootstrap and apply a linear model to each of them. A list of prediction is then generated for each of the bootstrap based on the training data. The predictions are then all compiled into a list. I applied that function to my object bootstrap_100 and set the output of that to prediction_list. I then converted that list to a matrix, which allowed me to run the code provided by Dr.Handel on the MADA website. That code calculated the confidence levels and median of the prediction variable.\n\nfit_and_predict &lt;- function(bootstrap_100) {\n  # Create an empty list to store predictions for all of the boots\n  prediction_list &lt;- list()\n  \n  # Loop through each bootstrap sample\n  for (i in 1:length(bootstrap_100$splits)) {\n    # Placing the current [i] bootstrap sample to 'bootstrap_sample object\n    bootstrap_sample &lt;- analysis(bootstrap_100$splits[[i]])\n    \n    # Fit a linear model\n    linear_model &lt;- lm(Y ~ ., data = bootstrap_sample)\n    \n    # Make predictions on the original train_data\n    boot_prediction &lt;- predict(linear_model, newdata = mavo2train_data)\n    \n    # Store predictions in the empty list created above\n    prediction_list[[i]] &lt;- boot_prediction\n  }\n  \n  return(prediction_list)\n}\n\n\n# Apply fit_and_predict function directly on bootstrap samples. This will cycle the function through each bootstrap sample\npredictions_list &lt;- fit_and_predict(bootstrap_100)\n\n# Verifying it worked. Running this should give me the 90 predicted observation for the first bootstrap sample\npredictions_list[1]\n\n[[1]]\n       1        2        3        4        5        6        7        8 \n3118.049 1894.039 2628.676 2165.134 2710.403 1370.259 2358.081 1990.458 \n       9       10       11       12       13       14       15       16 \n1601.518 2484.859 1648.276 1901.482 2341.715 3098.897 2059.736 2180.483 \n      17       18       19       20       21       22       23       24 \n3220.614 2687.877 2405.767 3170.552 3712.250 3041.984 1436.754 2585.173 \n      25       26       27       28       29       30       31       32 \n2984.581 2830.791 2399.264 1509.716 1775.081 1896.943 2634.975 3411.479 \n      33       34       35       36       37       38       39       40 \n1969.167 1376.645 2126.718 1713.278 2937.230 3386.286 2203.133 1649.541 \n      41       42       43       44       45       46       47       48 \n1984.038 2175.239 1860.417 3755.587 3170.453 3148.574 2088.211 2193.876 \n      49       50       51       52       53       54       55       56 \n3350.340 3253.971 2422.827 2771.180 2087.319 3427.878 2219.219 1757.332 \n      57       58       59       60       61       62       63       64 \n2766.498 2116.794 3056.978 2011.106 2952.359 1903.138 1427.501 3221.252 \n      65       66       67       68       69       70       71       72 \n1668.625 3050.249 3108.021 1451.672 2438.102 2193.159 2710.286 2762.986 \n      73       74       75       76       77       78       79       80 \n2212.214 2418.232 1805.806 1794.256 2880.903 3037.884 1483.078 2785.440 \n      81       82       83       84       85       86       87       88 \n2271.733 2790.511 1587.803 3276.106 2825.824 1720.098 1793.404 3048.518 \n      89       90 \n3263.245 3139.465 \n\n# The following line was provided by Dr. Handel. This can extract a single (the 1st one in this case) bootstrap sample into a data frame called dat_sample\ndat_sample = rsample::analysis(bootstrap_100$splits[[1]])\n\n# I then converted the list to matrix, so the following code can be ran.\npredictions_matrix &lt;- do.call(rbind, predictions_list)\n\n# The following code was based off of Dr. Handel's code\npredictions &lt;- predictions_matrix |&gt; apply(2, quantile,  c(0.055, 0.5, 0.945)) |&gt;  t()\n\nI then utilized ChatGPT to create the general gist of dataframe and plot below and editted it accordingly. I applied the observed values of the All_model to Observed and the predicted value to PointEstimate. The LowerBound, UpperBound, and the Median were all procured from the prediction list created from the function applied to the bootstrap.\n\n# Create a data frame containing the observed values and predictions\nplot_data &lt;- data.frame(\n  Observed = all_fit$Y,  # Observed values\n  PointEstimate = all_fit$.pred,  # Point estimate/ Original Prediction\n  Median = predictions[, 2],  # Median\n  LowerBound = predictions[, 1],  # Lower confidence bound\n  UpperBound = predictions[, 3]   # Upper confidence bound\n)\n\n# Create the plot with the X-axis being the original observed values on the x-axis and the point estimate on the y-axis. The original predictors are color coded in black. The median is in red, and the error bars(based on the UpperBound and LowerBound) or the confidence interval is in blue. \np4 &lt;- ggplot(plot_data, aes(x = Observed, y = PointEstimate)) +\n  geom_point(color = \"black\") +  # Point estimate/ original observed predictions\n  geom_errorbar(aes(ymin = LowerBound, ymax = UpperBound), width = 0.1, color = \"blue\") +  # Confidence interval\n  geom_point(aes(y = Median), color = \"red\") +  # Median\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"black\") +  # 45 degree line\n  labs(x = \"Observed Values\", y = \"Predicted Values\", title = \"Observed vs. Predicted Values for Model 2\") +\n  xlim(0, 6000) + ylim(0, 6000)+\n  theme_bw()  # Theme\n\n# Print the plot\nprint(p4)\n\n\n\n\nWhen observing the graph, there are a lot of overlaps between the prediction medians (sourced from the bootstrap samples) and the observed values (provided from the original fit). Despite it’s generally good fit, there are still a few signs of scattering, which might indicate other factors might still be influencing the data. Both the newly provided predicted medians and original follows the 45 degree angle line quite well. This shows that both that the predicted values and observed values from the original fit and the bootstrap fits are both fairly similar, which indicates a sign of a good model."
  },
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  }
]